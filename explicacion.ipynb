{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e3066d",
   "metadata": {},
   "source": [
    "# Análisis de Cabezas de Segmentación Personalizadas para YOLO\n",
    "\n",
    "## Resumen Ejecutivo\n",
    "\n",
    "Tienes dos implementaciones alternativas a la cabeza de segmentación original de YOLO:\n",
    "\n",
    "| Archivo | Enfoque | Inspiración |\n",
    "|---------|---------|-------------|\n",
    "| `head_enhanced.py` | Evolutivo - mejora la arquitectura existente | Mejoras incrementales sobre YOLO |\n",
    "| `head_attention.py` | Revolucionario - cambia el paradigma | Mask2Former (transformers) |\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Cómo Funciona YOLO-Seg Original\n",
    "\n",
    "Antes de entender las modificaciones, repasemos cómo funciona la segmentación original de YOLO:\n",
    "\n",
    "```\n",
    "Features del backbone → Prototipos (32) → Coeficientes por detección → Máscara = Σ(coef × prototipo)\n",
    "```\n",
    "\n",
    "### Componentes clave:\n",
    "\n",
    "1. **Proto (Prototipos)**: Genera 32 \"plantillas\" de máscara desde las features de mayor resolución (`x[0]`)\n",
    "2. **Coeficientes**: Cada detección predice 32 números que indican \"cuánto\" de cada prototipo usar\n",
    "3. **Combinación lineal**: La máscara final es `máscara = Σ(coef_i × prototipo_i)`\n",
    "\n",
    "### Limitaciones del original:\n",
    "- Solo 32 prototipos → capacidad limitada para formas complejas\n",
    "- Solo usa una escala (`x[0]`) → pierde contexto global\n",
    "- Combinación puramente lineal → no puede modelar interacciones complejas\n",
    "\n",
    "---\n",
    "\n",
    "## 2. head_enhanced.py - Mejoras Evolutivas\n",
    "\n",
    "Este archivo mantiene la filosofía de YOLO (prototipos + coeficientes) pero la mejora en tres aspectos:\n",
    "\n",
    "### Mejora A: Más Prototipos y Canales\n",
    "\n",
    "```python\n",
    "# Original YOLO\n",
    "nm = 32   # prototipos\n",
    "npr = 256 # canales intermedios\n",
    "\n",
    "# Enhanced\n",
    "nm = 64   # 2x más prototipos\n",
    "npr = 512 # 2x más canales\n",
    "```\n",
    "\n",
    "**¿Por qué ayuda?** Más prototipos = más \"plantillas base\" disponibles = mayor capacidad para representar formas diversas.\n",
    "\n",
    "### Mejora B: MultiScaleProto - Prototipos Multi-escala\n",
    "\n",
    "```python\n",
    "class MultiScaleProto(nn.Module):\n",
    "    \"\"\"\n",
    "    En vez de usar SOLO x[0] (alta resolución), fusiona TODAS las escalas:\n",
    "    - x[0]: 80×80 - detalles finos (bordes, texturas)\n",
    "    - x[1]: 40×40 - partes de objetos\n",
    "    - x[2]: 20×20 - contexto global (qué tipo de objeto es)\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "**Flujo de datos:**\n",
    "\n",
    "```\n",
    "x[0] (256, 80, 80) ──┐\n",
    "                     │\n",
    "x[1] (512, 40, 40) ──┼── Proyectar a canales comunes ──→ Alinear resoluciones ──→ Concatenar ──→ Fusionar ──→ Prototipos\n",
    "                     │\n",
    "x[2] (1024, 20, 20) ─┘\n",
    "```\n",
    "\n",
    "**¿Por qué ayuda?** Los prototipos ahora \"entienden\" tanto los detalles finos como el contexto semántico.\n",
    "\n",
    "### Mejora C: MaskRefiner - Refinamiento Post-proceso\n",
    "\n",
    "```python\n",
    "class MaskRefiner(nn.Module):\n",
    "    \"\"\"\n",
    "    Después de combinar prototipos, una red adicional \"pule\" la máscara:\n",
    "    1. Observa la máscara aproximada\n",
    "    2. Observa las features originales (contexto)\n",
    "    3. Predice una CORRECCIÓN residual\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "**Flujo:**\n",
    "\n",
    "```\n",
    "Máscara aproximada ──┐\n",
    "                     ├── Concatenar ──→ Red de refinamiento ──→ Corrección\n",
    "Features originales ─┘\n",
    "\n",
    "Máscara final = Máscara aproximada + Corrección (conexión residual)\n",
    "```\n",
    "\n",
    "**¿Por qué ayuda?** Puede corregir errores de la combinación lineal, especialmente en bordes complejos.\n",
    "\n",
    "### Arquitectura Completa de SegmentEnhanced\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                           SegmentEnhanced                                    │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│  DETECCIÓN (igual que YOLO original)                                        │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐   │\n",
    "│  │ cv2[i]: Features → BBox regression (4 × reg_max valores)            │   │\n",
    "│  │ cv3[i]: Features → Class scores (nc clases)                         │   │\n",
    "│  │ DFL: Distribución → valores continuos de bbox                       │   │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘   │\n",
    "│                                                                              │\n",
    "│  SEGMENTACIÓN MEJORADA                                                      │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐   │\n",
    "│  │ MultiScaleProto: [x0, x1, x2] → Prototipos (B, 64, H×2, W×2)        │   │\n",
    "│  │ cv4[i]: Features → Coeficientes de máscara (64 por anchor)          │   │\n",
    "│  │ MaskRefiner: Máscara cruda → Máscara refinada (opcional)            │   │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘   │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Salida durante entrenamiento:\n",
    "```python\n",
    "return x, mc, proto\n",
    "# x: predicciones de detección por escala\n",
    "# mc: coeficientes de máscara (B, 64, num_anchors)\n",
    "# proto: prototipos (B, 64, H×2, W×2)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 3. head_attention.py - Enfoque con Atención (estilo Mask2Former)\n",
    "\n",
    "Este archivo cambia completamente el paradigma: en vez de prototipos + coeficientes, usa **queries aprendibles** y **atención enmascarada**.\n",
    "\n",
    "### Conceptos Clave de Mask2Former Implementados\n",
    "\n",
    "1. **Queries Aprendibles**: En vez de prototipos fijos, N \"preguntas\" que aprenden a buscar objetos\n",
    "2. **Masked Cross-Attention**: La atención se restringe a regiones donde probablemente hay objetos\n",
    "3. **Predicción directa**: Cada query produce directamente una máscara via dot-product\n",
    "\n",
    "### MaskedCrossAttention - El Corazón del Sistema\n",
    "\n",
    "```python\n",
    "class MaskedCrossAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Atención cruzada donde los queries solo \"miran\" regiones relevantes.\n",
    "    \n",
    "    Analogía: Buscas tu gato en una foto. En vez de mirar cada píxel,\n",
    "    primero identificas áreas probables (sofá, cama) y luego miras\n",
    "    con detalle SOLO esas áreas.\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "**Flujo matemático:**\n",
    "\n",
    "```\n",
    "1. Q = query × W_q     # Proyectar queries\n",
    "2. K = features × W_k  # Proyectar features como keys\n",
    "3. V = features × W_v  # Proyectar features como values\n",
    "\n",
    "4. Attention = softmax((Q × K^T) / √d)  # Pesos de atención\n",
    "\n",
    "5. Si hay máscara: Attention[~mask] = -inf → softmax → 0\n",
    "   (Los queries IGNORAN posiciones enmascaradas)\n",
    "\n",
    "6. Output = Attention × V  # Información ponderada\n",
    "```\n",
    "\n",
    "### QueryMaskDecoder - Decodificador Iterativo\n",
    "\n",
    "```python\n",
    "class QueryMaskDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Proceso iterativo:\n",
    "    1. Queries iniciales (aprendibles)\n",
    "    2. Por cada capa del decoder:\n",
    "       a. Predecir máscara actual con queries\n",
    "       b. Usar esa máscara para crear attention_mask\n",
    "       c. Cross-attention enmascarada → actualizar queries\n",
    "    3. Predicción final de máscaras\n",
    "    \"\"\"\n",
    "```\n",
    "\n",
    "**Flujo por capa:**\n",
    "\n",
    "```\n",
    "Queries ──→ Predecir máscara temporal ──→ Crear attention_mask\n",
    "                                              │\n",
    "                                              ▼\n",
    "                                    Cross-Attention enmascarada\n",
    "                                              │\n",
    "                                              ▼\n",
    "                                    Queries actualizados ──→ FFN ──→ Siguiente capa\n",
    "```\n",
    "\n",
    "**¿Por qué es iterativo?** Cada iteración refina la predicción:\n",
    "- Iteración 1: \"Creo que hay algo aquí\" (máscara borrosa)\n",
    "- Iteración 2: \"Sí, es un objeto, ajusto la forma\"\n",
    "- Iteración N: \"Esta es la máscara precisa\"\n",
    "\n",
    "### Predicción de Máscaras via Dot-Product\n",
    "\n",
    "```python\n",
    "def _predict_mask(self, queries, mask_features):\n",
    "    # Proyectar queries\n",
    "    mask_embed = self.mask_head(queries)  # (B, N, C)\n",
    "    \n",
    "    # Dot product: cada query \"pregunta\" a cada posición espacial\n",
    "    masks = torch.bmm(mask_embed, mask_features.flatten(2))  # (B, N, HW)\n",
    "    \n",
    "    # Reshape a espacial\n",
    "    return masks.view(B, N, H, W)\n",
    "```\n",
    "\n",
    "**Intuición:** Cada query tiene un \"embedding de máscara\" que, cuando hace dot-product con las features, produce valores altos donde el objeto está presente.\n",
    "\n",
    "### Arquitectura Completa de SegmentAttention\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────────────────────┐\n",
    "│                           SegmentAttention                                   │\n",
    "├─────────────────────────────────────────────────────────────────────────────┤\n",
    "│  DETECCIÓN (igual que YOLO)                                                 │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐   │\n",
    "│  │ cv2[i], cv3[i], DFL - idéntico a YOLO                               │   │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘   │\n",
    "│                                                                              │\n",
    "│  SEGMENTACIÓN CON ATENCIÓN                                                  │\n",
    "│  ┌─────────────────────────────────────────────────────────────────────┐   │\n",
    "│  │ input_proj: Proyectar features a embed_dim (256)                    │   │\n",
    "│  │ mask_feature_proj: Generar features de alta resolución para máscaras│   │\n",
    "│  │                                                                      │   │\n",
    "│  │ QueryMaskDecoder:                                                    │   │\n",
    "│  │   ├── query_embed: N queries aprendibles (embeddings)               │   │\n",
    "│  │   ├── decoder_layers: [DecoderLayer × num_layers]                   │   │\n",
    "│  │   │     └── MaskedCrossAttention + FFN                              │   │\n",
    "│  │   └── mask_head: Query → máscara via dot-product                    │   │\n",
    "│  │                                                                      │   │\n",
    "│  │ class_head: Query embedding → predicción de clase (+1 para \"no obj\")│   │\n",
    "│  └─────────────────────────────────────────────────────────────────────┘   │\n",
    "└─────────────────────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Salida durante entrenamiento:\n",
    "```python\n",
    "return {\n",
    "    'det': x,                      # Predicciones de detección\n",
    "    'pred_masks': pred_masks,      # (B, num_queries, H, W)\n",
    "    'pred_classes': pred_classes,  # (B, num_queries, nc+1)\n",
    "    'query_embeddings': query_embeddings,\n",
    "    'intermediate_masks': intermediate_masks,  # Para auxiliary loss\n",
    "    'mask_features': mask_features,\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Comparación Detallada\n",
    "\n",
    "### Tabla de Diferencias Técnicas\n",
    "\n",
    "| Aspecto | YOLO Original | SegmentEnhanced | SegmentAttention |\n",
    "|---------|---------------|-----------------|------------------|\n",
    "| **Paradigma** | Prototipos + coefs | Prototipos + coefs mejorados | Queries + atención |\n",
    "| **Prototipos/Queries** | 32 fijos | 64 multi-escala | N queries aprendibles |\n",
    "| **Escalas usadas** | Solo x[0] | Todas (x[0], x[1], x[2]) | Principalmente x[0] + proyección |\n",
    "| **Atención** | No | No | Masked cross-attention |\n",
    "| **Refinamiento** | No | Sí (MaskRefiner) | Implícito (iterativo) |\n",
    "| **Clasificación** | Via detección | Via detección | Independiente por query |\n",
    "| **Complejidad** | O(n) | O(n) con más ops | O(n²) por atención |\n",
    "\n",
    "### ¿Cuándo Usar Cada Uno?\n",
    "\n",
    "**SegmentEnhanced** es mejor cuando:\n",
    "- Necesitas compatibilidad máxima con el pipeline de YOLO existente\n",
    "- La velocidad es crítica\n",
    "- Quieres mejoras incrementales sin cambiar el paradigma\n",
    "- El entrenamiento debe ser similar al original\n",
    "\n",
    "**SegmentAttention** es mejor cuando:\n",
    "- Necesitas máxima precisión en bordes y formas complejas\n",
    "- Tienes objetos pequeños o muy superpuestos\n",
    "- Puedes tolerar algo de latencia adicional\n",
    "- Estás dispuesto a adaptar el pipeline de entrenamiento (Hungarian matching, etc.)\n",
    "\n",
    "### Complejidad Computacional\n",
    "\n",
    "```\n",
    "YOLO Original:\n",
    "- Prototipos: Conv(x[0]) → O(C × H × W × nm)\n",
    "- Combinación: coef @ proto → O(B × num_det × nm × H × W)\n",
    "\n",
    "SegmentEnhanced:\n",
    "- Prototipos: MultiScale → ~3× más operaciones\n",
    "- Combinación: igual\n",
    "- Refinamiento: +O(B × num_det × H × W × hidden_dim)\n",
    "\n",
    "SegmentAttention:\n",
    "- Proyección: O(C × H × W × embed_dim)\n",
    "- Atención: O(B × num_queries × (H×W)²) ← el cuello de botella\n",
    "- Predicción: O(B × num_queries × embed_dim × H × W)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Cambios Necesarios para Integración\n",
    "\n",
    "### Para SegmentEnhanced:\n",
    "\n",
    "1. **Registrar en `__init__.py`**:\n",
    "```python\n",
    "from .head_enhanced import SegmentEnhanced, MultiScaleProto, MaskRefiner\n",
    "```\n",
    "\n",
    "2. **Modificar `tasks.py`** para reconocer la clase:\n",
    "```python\n",
    "# En parse_model o donde se construye el modelo\n",
    "if m is SegmentEnhanced:\n",
    "    # Configuración similar a Segment original\n",
    "```\n",
    "\n",
    "3. **Loss**: Puede usar la misma loss que YOLO-seg original\n",
    "\n",
    "### Para SegmentAttention:\n",
    "\n",
    "1. **Registrar** igual que arriba\n",
    "\n",
    "2. **Loss function nueva**: Necesita:\n",
    "   - Hungarian matching (asignar queries a ground truth)\n",
    "   - Mask loss (BCE o Dice)\n",
    "   - Class loss (cross-entropy con \"no object\")\n",
    "   - Auxiliary losses en capas intermedias\n",
    "\n",
    "3. **Post-procesamiento**: Los queries son independientes de las detecciones de YOLO, necesitas:\n",
    "   - Filtrar queries con confianza < threshold\n",
    "   - O hacer matching entre queries y detecciones de YOLO\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Resumen Visual\n",
    "\n",
    "```\n",
    "YOLO Original:\n",
    "  Features ──→ [Proto] ──→ 32 plantillas ──→ Σ(coef × plantilla) ──→ Máscara\n",
    "                              ↑\n",
    "                        Solo una escala\n",
    "\n",
    "SegmentEnhanced:\n",
    "  [x0, x1, x2] ──→ [MultiScaleProto] ──→ 64 plantillas ──→ Σ(...) ──→ [Refiner] ──→ Máscara\n",
    "                         ↑                                              ↑\n",
    "                   Todas las escalas                              Corrección no-lineal\n",
    "\n",
    "SegmentAttention:\n",
    "  Features ──→ [Queries] ──→ Cross-Attention ──→ Cross-Attention ──→ ... ──→ Dot-Product ──→ Máscaras\n",
    "                  ↑              ↑ (masked)          ↑ (masked)\n",
    "            Aprendibles     Enfocada en regiones relevantes\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Conclusión\n",
    "\n",
    "Ambas implementaciones son mejoras válidas sobre YOLO original:\n",
    "\n",
    "- **SegmentEnhanced**: Evolución conservadora, fácil de integrar, mejoras modestas pero confiables\n",
    "- **SegmentAttention**: Cambio de paradigma, potencialmente mayor precisión, requiere más trabajo de integración\n",
    "\n",
    "La elección depende de tus prioridades: velocidad vs precisión, facilidad de integración vs potencial de mejora."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
